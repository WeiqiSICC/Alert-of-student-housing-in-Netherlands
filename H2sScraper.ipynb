{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start a new case, monitoting the web traffic\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getpass\n",
    "import lxml\n",
    "import logging\n",
    "logging.basicConfig(filename='scraper.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class h2s:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, user_name:str, pass_word:str, host_name:str, name_database:str, port:int):\n",
    "        '''\n",
    "        user_name:str the user name of MySQL connection\n",
    "        pass_word:str the password pf MySQL connection\n",
    "        host_name:str the host name of this RDB\n",
    "        port:str the number of host, should be a integer of 4\n",
    "\n",
    "        Note that init method has no output which is just a intialization\n",
    "\n",
    "        If you are working on your MySQL server, you need to use the connection below and which is the default value in __init__\n",
    "        '''\n",
    "\n",
    "        self.user_name = user_name\n",
    "        self.pass_word = pass_word \n",
    "        self.host_name = host_name\n",
    "        self.today = datetime.today()\n",
    "        self.port = port\n",
    "        self.name_database = name_database\n",
    "        try:\n",
    "            self.connection_str = f'mysql+pymysql://{user_name}:{pass_word}@{host_name}:{port}/{name_database}'\n",
    "            self.sqlEngine = create_engine(self.connection_str)\n",
    "            self.dbConnection = self.sqlEngine.connect()\n",
    "            logging.info(f'{self.today}: connection establised')\n",
    "        except:\n",
    "            print(f'ERROR in server connection, please check')\n",
    "\n",
    "    def h2sScraper (self,name_table):\n",
    "        '''\n",
    "        Note: If your are working with a MySQL server then use this\n",
    "        '''\n",
    "\n",
    "        self.name_table = name_table\n",
    "\n",
    "        ## this is a generator of a random user for the sake of privacy\n",
    "        ua = UserAgent()\n",
    "        UserAgent_random = ua.random\n",
    "        headers = {'User-Agent': UserAgent_random}\n",
    "\n",
    "        ## this is the link to h2s\n",
    "        page = requests.get(f'https://holland2stay.com/residences.html?&available_to_book=179&p={1}&product_list_limit=30', headers=headers)\n",
    "        soup = BeautifulSoup(page.content,'lxml')\n",
    "\n",
    "        ## I am too lazy to rename this variable, this a is a the class called regi-item d-flex flex-wrap, wraps all resources that can be book directly\n",
    "        a = soup.find_all(class_ = 'regi-item d-flex flex-wrap')\n",
    "\n",
    "\n",
    "        ## lists for dataframe below\n",
    "        list_time = []\n",
    "        list_street_num = []\n",
    "        list_avalability = []\n",
    "        list_city = []\n",
    "        list_building = []\n",
    "        list_furnishment = []\n",
    "        list_num_floor = []\n",
    "        list_size = []\n",
    "        list_num_bedrooms = []\n",
    "        list_occupancy = []\n",
    "        list_contract = []\n",
    "        list_stay = []\n",
    "\n",
    "\n",
    "        for i in range(len(a)):\n",
    "\n",
    "            soup = BeautifulSoup(str(a[i]), 'lxml')\n",
    "            h4_element = soup.find('h4', class_='regularbold')\n",
    "            li = soup.find_all('li')\n",
    "            stree_num = h4_element.contents[0]\n",
    "            info = [element.text.strip() for element in li]\n",
    "            list_time.append(datetime.today())\n",
    "            list_street_num.append(stree_num)\n",
    "            list_avalability.append(info[0].replace('Available from',''))\n",
    "            list_city.append(info[1])\n",
    "            list_building.append(info[2])\n",
    "            list_furnishment.append(info[3])\n",
    "            list_num_floor.append(info[4]. replace('Floor ',''))\n",
    "            list_size.append(info[5])\n",
    "            list_num_bedrooms.append(info[6].replace('Bedrooms: ', ''))\n",
    "            list_occupancy.append(info[7].replace('Max occupancy: ', ''))\n",
    "            list_contract.append(info[8].replace('Contract type: ', ''))\n",
    "            list_stay.append(info[9].replace('Minimum stay: ', ''))\n",
    "\n",
    "        \n",
    "        self.update = pd.DataFrame({\"UpdateTime\": list_time, \"StreetNumber\" : list_street_num, \"Avalibility\": list_avalability, \"City\" : list_city, \"Building\" : list_building,\n",
    "                    \"Furnishment\" : list_furnishment, \"NumberFloor\" : list_num_floor, \"RoomSize\" : list_size, \"BedroomNumber\" : list_num_bedrooms,\"MaxOccupancy\":list_occupancy,\n",
    "                    \"ContractType\" : list_contract, \"MinimumStay\" : list_stay})\n",
    "        try:\n",
    "            old = pd.read_sql(f'SELECT * FROM {self.name_database}.{self.name_table}', self.sqlEngine)\n",
    "        except:\n",
    "            old = pd.DataFrame({\"UpdateTime\": [], \"StreetNumber\" : [], \"Avalibility\": [], \"City\" : [], \"Building\" : [],\n",
    "                    \"Furnishment\" : [], \"NumberFloor\" : [], \"RoomSize\" : [], \"BedroomNumber\" : [],\"MaxOccupancy\": [],\n",
    "                    \"ContractType\" : [], \"MinimumStay\" : []})\n",
    "\n",
    "\n",
    "        # Find missing rows, meaning to find what are already booked during time between this update and previous one\n",
    "        missing_rows = old[~old.isin(self.update)].dropna()\n",
    "        # Find new rows, meaning to find what are newly released\n",
    "        new_rows = self.update[~self.update.isin(old)].dropna()\n",
    "\n",
    "        ## export to MySQL as a temporary table\n",
    "        self.update.to_sql(name_table,if_exists=\"replace\",index=False ,con=self.dbConnection)\n",
    "        return new_rows, missing_rows, self.update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
